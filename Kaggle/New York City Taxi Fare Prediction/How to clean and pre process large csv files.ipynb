{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## Hi, i was having a hard time trying to load this huge data set as a pandas data frame on my pc, so i searched for alternative ways of doing this as i don't want to pay for cloud services and don't have access to better machines.\n### actually the solution was pretty simple, so i'm sharing what i ended up with, maybe i can help other struggling with the same problem.\nobs: this approach won't let you analyse or summarize the data as pandas data frames would (at least not easily),\nany criticism or tips are welcomed."
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import csv\nfrom datetime import datetime\n\n\ndef clean_data(input_data_path='../input/train.csv', output_data_path='../data/train_cleaned.csv'):\n    \"\"\"\n    Clean the data set, removing any row with missing values,\n    delimiter longitudes and latitudes to fit only NY city values,\n    only fare amount greater than 0,\n    and passenger count greater than 0 and lesser than 7,\n    i also removed the header as i'm using tensorflow to load data.\n    :param input_data_path: path containing the raw data set.\n    :param output_data_path: path to write the cleaned data.\n    \"\"\"\n    with open(input_data_path, 'r') as inp, open(output_data_path, 'w', newline='') as out:\n        writer = csv.writer(out)\n        count = 0\n        for row in csv.reader(inp):\n            # Remove header\n            if count > 0:\n                # Only rows with non-null values\n                if len(row) == 8:\n                    try:\n                        fare_amount = float(row[1])\n                        pickup_longitude = float(row[3])\n                        pickup_latitude = float(row[4])\n                        dropoff_longitude = float(row[5])\n                        dropoff_latitude = float(row[6])\n                        passenger_count = float(row[7])\n                        if ((-76 <= pickup_longitude <= -72) and (-76 <= dropoff_longitude <= -72) and\n                                (38 <= pickup_latitude <= 42) and (38 <= dropoff_latitude <= 42) and\n                                (1 <= passenger_count <= 6) and fare_amount > 0):\n                            writer.writerow(row)\n                    except:\n                        pass\n            count += 1\n\n\ndef pre_process_train_data(input_data_path='data/train_cleaned.csv', output_data_path='data/train_processed.csv'):\n    \"\"\"\n    Pre process the train data, deriving, year, month, day and hour for each row.\n    :param input_data_path: path containing the full data set.\n    :param output_data_path: path to write the pre processed set.\n    \"\"\"\n    with open(input_data_path, 'r') as inp, open(output_data_path, 'w', newline='') as out:\n        writer = csv.writer(out)\n        for row in csv.reader(inp):\n            pickup_datetime = datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S %Z')\n            row.append(pickup_datetime.year)\n            row.append(pickup_datetime.month)\n            row.append(pickup_datetime.day)\n            row.append(pickup_datetime.hour)\n            row.append(pickup_datetime.weekday())\n            writer.writerow(row)\n\n\ndef pre_process_test_data(input_data_path='data/test.csv', output_data_path='data/test_processed.csv'):\n    \"\"\"\n    Pre process the test data, deriving, year, month, day and hour for each row.\n    :param input_data_path: path containing the full data set.\n    :param output_data_path: path to write the pre processed set.\n    \"\"\"\n    with open(input_data_path, 'r') as inp, open(output_data_path, 'w', newline='') as out:\n        writer = csv.writer(out)\n        count = 0\n        for row in csv.reader(inp):\n            if count > 0:\n                pickup_datetime = datetime.strptime(row[1], '%Y-%m-%d %H:%M:%S %Z')\n                row.append(pickup_datetime.year)\n                row.append(pickup_datetime.month)\n                row.append(pickup_datetime.day)\n                row.append(pickup_datetime.hour)\n                row.append(pickup_datetime.weekday())\n                writer.writerow(row)\n            else:\n                # Only the header\n                writer.writerow(row)\n            count += 1\n\n\ndef split_data(input_data_path, train_data_path, validation_data_path, ratio=30):\n    \"\"\"\n    Splits the csv file (meant to generate train and validation sets).\n    :param input_data_path: path containing the full data set.\n    :param train_data_path: path to write the train set.\n    :param validation_data_path: path to write the validation set.\n    :param ratio: ration to split train and validation sets, (default: 1 of every 30 rows will be validation or 0,033%)\n    \"\"\"\n    with open(input_data_path, 'r') as inp, open(train_data_path, 'w', newline='') as out1, \\\n            open(validation_data_path, 'w', newline='') as out2:\n        writer1 = csv.writer(out1)\n        writer2 = csv.writer(out2)\n        count = 0\n        for row in csv.reader(inp):\n            if count % ratio == 0:\n                writer2.writerow(row)\n            else:\n                writer1.writerow(row)\n            count += 1\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}