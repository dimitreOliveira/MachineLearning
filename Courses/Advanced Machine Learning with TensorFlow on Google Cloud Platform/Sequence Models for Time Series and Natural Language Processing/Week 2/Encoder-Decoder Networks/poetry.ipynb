{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation using tensor2tensor on Cloud ML Engine\n",
    "\n",
    "This notebook illustrates using the <a href=\"https://github.com/tensorflow/tensor2tensor\">tensor2tensor</a> library to do from-scratch, distributed training of a poetry model. Then, the trained model is used to complete new poems.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Install tensor2tensor, and specify Google Cloud Platform project and bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary packages. tensor2tensor will give us the Transformer model. Project Gutenberg gives us access to historical poems.\n",
    "\n",
    "\n",
    "<b>p.s.</b> Note that this notebook uses Python2 because Project Gutenberg relies on BSD-DB which was deprecated in Python 3 and removed from the standard library.\n",
    "tensor2tensor itself can be used on Python 3. It's just Project Gutenberg that has this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard==1.8.0\n",
      "tensorflow==1.8.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install tensor2tensor==1.13.1 tensorflow==1.13.1 tensorflow-serving-api==1.13 gutenberg \n",
    "pip install tensorflow_hub \n",
    "\n",
    "# install from sou\n",
    "#git clone https://github.com/tensorflow/tensor2tensor.git\n",
    "#cd tensor2tensor\n",
    "#yes | pip install --user -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following cell does not reflect the version of tensorflow and tensor2tensor that you just installed, click **\"Reset Session\"** on the notebook so that the Python environment picks up the new packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh-tensorflow==0.0.5\n",
      "tensor2tensor==1.13.1\n",
      "tensorboard==1.13.1\n",
      "tensorflow==1.13.1\n",
      "tensorflow-datasets==1.0.2\n",
      "tensorflow-estimator==1.13.0\n",
      "tensorflow-hub==0.4.0\n",
      "tensorflow-metadata==0.13.0\n",
      "tensorflow-probability==0.6.0\n",
      "tensorflow-serving-api==1.13.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'qwiklabs-gcp-273e0fc7a73ebe0d' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-273e0fc7a73ebe0d' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# this is what this notebook is demonstrating\n",
    "PROBLEM= 'poetry_line_problem'\n",
    "\n",
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['PROBLEM'] = PROBLEM\n",
    "\n",
    "#os.environ['PATH'] = os.environ['PATH'] + ':' + os.getcwd() + '/tensor2tensor/tensor2tensor/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "We will get some <a href=\"https://www.gutenberg.org/wiki/Poetry_(Bookshelf)\">poetry anthologies</a> from Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf data/poetry\n",
    "mkdir -p data/poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote lines 0 to 2802 from Victorian songs\n",
      "Wrote lines 2802 to 7503 from Baldwin collection\n",
      "Wrote lines 7503 to 14069 from Swinburne collection\n",
      "Wrote lines 14069 to 14926 from Blake\n",
      "Wrote lines 14926 to 42441 from Bulchevys collection\n",
      "Wrote lines 42441 to 51789 from Palgrave-Pearse collection\n",
      "Wrote lines 51789 to 56298 from Knowles collection\n"
     ]
    }
   ],
   "source": [
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "import re\n",
    "\n",
    "books = [\n",
    "  # bookid, skip N lines\n",
    "  (26715, 1000, 'Victorian songs'),\n",
    "  (30235, 580, 'Baldwin collection'),\n",
    "  (35402, 710, 'Swinburne collection'),\n",
    "  (574, 15, 'Blake'),\n",
    "  (1304, 172, 'Bulchevys collection'),\n",
    "  (19221, 223, 'Palgrave-Pearse collection'),\n",
    "  (15553, 522, 'Knowles collection') \n",
    "]\n",
    "\n",
    "with open('data/poetry/raw.txt', 'w') as ofp:\n",
    "  lineno = 0\n",
    "  for (id_nr, toskip, title) in books:\n",
    "    startline = lineno\n",
    "    text = strip_headers(load_etext(id_nr)).strip()\n",
    "    lines = text.split('\\n')[toskip:]\n",
    "    # any line that is all upper case is a title or author name\n",
    "    # also don't want any lines with years (numbers)\n",
    "    for line in lines:\n",
    "      if (len(line) > 0 \n",
    "          and line.upper() != line \n",
    "          and not re.match('.*[0-9]+.*', line)\n",
    "          and len(line) < 50\n",
    "         ):\n",
    "        cleaned = re.sub('[^a-z\\'\\-]+', ' ', line.strip().lower())\n",
    "        ofp.write(cleaned)\n",
    "        ofp.write('\\n')\n",
    "        lineno = lineno + 1\n",
    "      else:\n",
    "        ofp.write('\\n')\n",
    "    print('Wrote lines {} to {} from {}'.format(startline, lineno, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88133 data/poetry/raw.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/poetry/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset\n",
    "\n",
    "We are going to train a machine learning model to write poetry given a starting point. We'll give it one line, and it is going to tell us the next line.  So, naturally, we will train it on real poetry. Our feature will be a line of a poem and the label will be next line of that poem.\n",
    "<p>\n",
    "Our training dataset will consist of two files.  The first file will consist of the input lines of poetry and the other file will consist of the corresponding output lines, one output line per input line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/poetry/raw.txt', 'r') as rawfp,\\\n",
    "  open('data/poetry/input.txt', 'w') as infp,\\\n",
    "  open('data/poetry/output.txt', 'w') as outfp:\n",
    "    \n",
    "    prev_line = ''\n",
    "    for curr_line in rawfp:\n",
    "        curr_line = curr_line.strip()\n",
    "        # poems break at empty lines, so this ensures we train only\n",
    "        # on lines of the same poem\n",
    "        if len(prev_line) > 0 and len(curr_line) > 0:       \n",
    "            infp.write(prev_line + '\\n')\n",
    "            outfp.write(curr_line + '\\n')\n",
    "        prev_line = curr_line      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> data/poetry/input.txt <==\r\n",
      "i sat beside the streamlet\r\n",
      "i watched the water flow\r\n",
      "as we together watched it\r\n",
      "one little year ago\r\n",
      "the soft rain pattered on the leaves\r\n",
      "\r\n",
      "==> data/poetry/output.txt <==\r\n",
      "i watched the water flow\r\n",
      "as we together watched it\r\n",
      "one little year ago\r\n",
      "the soft rain pattered on the leaves\r\n",
      "the april grass was wet\r\n",
      "\r\n",
      "==> data/poetry/raw.txt <==\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 data/poetry/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to generate the data beforehand -- instead, we can have Tensor2Tensor create the training dataset for us. So, in the code below, I will use only data/poetry/raw.txt -- obviously, this allows us to productionize our model better.  Simply keep collecting raw data and generate the training/test data at the time of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up problem\n",
    "The Problem in tensor2tensor is where you specify parameters like the size of your vocabulary and where to get the training data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf poetry\n",
    "mkdir -p poetry/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing poetry/trainer/problem.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile poetry/trainer/problem.py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.models import transformer\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import generator_utils\n",
    "\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "\n",
    "@registry.register_problem\n",
    "class PoetryLineProblem(text_problems.Text2TextProblem):\n",
    "  \"\"\"Predict next line of poetry from the last line. From Gutenberg texts.\"\"\"\n",
    "\n",
    "  @property\n",
    "  def approx_vocab_size(self):\n",
    "    return 2**13  # ~8k\n",
    "\n",
    "  @property\n",
    "  def is_generate_per_split(self):\n",
    "    # generate_data will NOT shard the data into TRAIN and EVAL for us.\n",
    "    return False\n",
    "\n",
    "  @property\n",
    "  def dataset_splits(self):\n",
    "    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n",
    "    # 10% evaluation data\n",
    "    return [{\n",
    "        \"split\": problem.DatasetSplit.TRAIN,\n",
    "        \"shards\": 90,\n",
    "    }, {\n",
    "        \"split\": problem.DatasetSplit.EVAL,\n",
    "        \"shards\": 10,\n",
    "    }]\n",
    "\n",
    "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
    "    with open('data/poetry/raw.txt', 'r') as rawfp:\n",
    "      prev_line = ''\n",
    "      for curr_line in rawfp:\n",
    "        curr_line = curr_line.strip()\n",
    "        # poems break at empty lines, so this ensures we train only\n",
    "        # on lines of the same poem\n",
    "        if len(prev_line) > 0 and len(curr_line) > 0:       \n",
    "            yield {\n",
    "                \"inputs\": prev_line,\n",
    "                \"targets\": curr_line\n",
    "            }\n",
    "        prev_line = curr_line          \n",
    "\n",
    "\n",
    "# Smaller than the typical translate model, and with more regularization\n",
    "@registry.register_hparams\n",
    "def transformer_poetry():\n",
    "  hparams = transformer.transformer_base()\n",
    "  hparams.num_hidden_layers = 2\n",
    "  hparams.hidden_size = 128\n",
    "  hparams.filter_size = 512\n",
    "  hparams.num_heads = 4\n",
    "  hparams.attention_dropout = 0.6\n",
    "  hparams.layer_prepostprocess_dropout = 0.6\n",
    "  hparams.learning_rate = 0.05\n",
    "  return hparams\n",
    "\n",
    "@registry.register_hparams\n",
    "def transformer_poetry_tpu():\n",
    "  hparams = transformer_poetry()\n",
    "  transformer.update_hparams_for_tpu(hparams)\n",
    "  return hparams\n",
    "\n",
    "# hyperparameter tuning ranges\n",
    "@registry.register_ranged_hparams\n",
    "def transformer_poetry_range(rhp):\n",
    "  rhp.set_float(\"learning_rate\", 0.05, 0.25, scale=rhp.LOG_SCALE)\n",
    "  rhp.set_int(\"num_hidden_layers\", 2, 4)\n",
    "  rhp.set_discrete(\"hidden_size\", [128, 256, 512])\n",
    "  rhp.set_float(\"attention_dropout\", 0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing poetry/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile poetry/trainer/__init__.py\n",
    "from . import problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing poetry/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile poetry/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "  'tensor2tensor'\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='poetry',\n",
    "    version='0.1',\n",
    "    author = 'Google',\n",
    "    author_email = 'training-feedback@cloud.google.com',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Poetry Line Problem',\n",
    "    requires=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch poetry/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poetry\r\n",
      "poetry/setup.py\r\n",
      "poetry/trainer\r\n",
      "poetry/trainer/problem.py\r\n",
      "poetry/trainer/__init__.py\r\n",
      "poetry/__init__.py\r\n"
     ]
    }
   ],
   "source": [
    "!find poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data \n",
    "\n",
    "Our problem (translation) requires the creation of text sequences from the training dataset.  This is done using t2t-datagen and the Problem defined in the previous section.\n",
    "\n",
    "(Ignore any runtime warnings about np.float64. they are harmless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "INFO:tensorflow:Generating problems:\n",
      "    poetry:\n",
      "      * poetry_line_problem\n",
      "INFO:tensorflow:Generating data for poetry_line_problem.\n",
      "INFO:tensorflow:Generating vocab file: ./t2t_data/vocab.poetry_line_problem.8192.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 1189\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 676\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 704\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 702\n",
      "INFO:tensorflow:Trying min_count 250\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 2025\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 1097\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 1130\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 1129\n",
      "INFO:tensorflow:Trying min_count 125\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 3386\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 1756\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 1798\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 1799\n",
      "INFO:tensorflow:Trying min_count 62\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 5620\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 2771\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 2832\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 2823\n",
      "INFO:tensorflow:Trying min_count 31\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 9026\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 4270\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 4362\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 4363\n",
      "INFO:tensorflow:Trying min_count 15\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 14356\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 6615\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 6754\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 6739\n",
      "INFO:tensorflow:Trying min_count 7\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 22520\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 10075\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 10220\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 10191\n",
      "INFO:tensorflow:Trying min_count 11\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 17325\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 7831\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 7973\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 7957\n",
      "INFO:tensorflow:Trying min_count 9\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 19507\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 8776\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 8943\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 8938\n",
      "INFO:tensorflow:Trying min_count 10\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 18370\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 8289\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 8432\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 8425\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generated 44341 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/data_generators/generator_utils.py:469: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=./t2t_data\n",
    "TMP_DIR=$DATA_DIR/tmp\n",
    "rm -rf $DATA_DIR $TMP_DIR\n",
    "mkdir -p $DATA_DIR $TMP_DIR\n",
    "# Generate data\n",
    "t2t-datagen \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see the files that were output. If you see a broken pipe error, please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poetry_line_problem-dev-00000-of-00010\r\n",
      "poetry_line_problem-dev-00001-of-00010\r\n",
      "poetry_line_problem-dev-00002-of-00010\r\n",
      "poetry_line_problem-dev-00003-of-00010\r\n",
      "poetry_line_problem-dev-00004-of-00010\r\n",
      "poetry_line_problem-dev-00005-of-00010\r\n",
      "poetry_line_problem-dev-00006-of-00010\r\n",
      "poetry_line_problem-dev-00007-of-00010\r\n",
      "poetry_line_problem-dev-00008-of-00010\r\n",
      "poetry_line_problem-dev-00009-of-00010\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls t2t_data | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Cloud ML Engine access to data\n",
    "\n",
    "Copy the data to Google Cloud Storage, and then provide access to the data. `gsutil` throws an error when removing an empty bucket, so you may see an error the first time this code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying file://./t2t_data/poetry_line_problem-dev-00000-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 32.3 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00001-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 64.6 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00002-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 97.0 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00003-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/129.4 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00004-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/161.9 KiB]                                                \r",
      "/ [1 files][129.4 KiB/161.9 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00005-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [1 files][161.9 KiB/194.1 KiB]                                                \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00006-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [2/101 files][161.9 KiB/  3.2 MiB]   4% Done                                  \r",
      "/ [2/101 files][194.1 KiB/  3.2 MiB]   5% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00007-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [3/101 files][226.4 KiB/  3.2 MiB]   6% Done                                  \r",
      "/ [3/101 files][226.4 KiB/  3.2 MiB]   6% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00008-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [4/101 files][226.4 KiB/  3.2 MiB]   6% Done                                  \r",
      "/ [4/101 files][226.4 KiB/  3.2 MiB]   6% Done                                  \r",
      "/ [5/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "/ [6/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-dev-00009-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [6/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00000-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [6/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "/ [7/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00001-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [7/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00003-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00002-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [8/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "/ [9/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "/ [9/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "/ [9/101 files][291.1 KiB/  3.2 MiB]   8% Done                                  \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00004-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [10/101 files][453.8 KiB/  3.2 MiB]  13% Done                                 \r",
      "/ [10/101 files][453.8 KiB/  3.2 MiB]  13% Done                                 \r",
      "/ [11/101 files][486.3 KiB/  3.2 MiB]  14% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00005-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [11/101 files][486.3 KiB/  3.2 MiB]  14% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00006-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [12/101 files][518.8 KiB/  3.2 MiB]  15% Done                                 \r",
      "/ [12/101 files][518.8 KiB/  3.2 MiB]  15% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00007-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [13/101 files][518.8 KiB/  3.2 MiB]  15% Done                                 \r",
      "-\r",
      "- [13/101 files][518.8 KiB/  3.2 MiB]  15% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00008-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00009-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [14/101 files][551.3 KiB/  3.2 MiB]  16% Done                                 \r",
      "- [15/101 files][551.3 KiB/  3.2 MiB]  16% Done                                 \r",
      "- [15/101 files][551.3 KiB/  3.2 MiB]  16% Done                                 \r",
      "- [15/101 files][551.3 KiB/  3.2 MiB]  16% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00010-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [16/101 files][583.8 KiB/  3.2 MiB]  17% Done                                 \r",
      "- [16/101 files][583.8 KiB/  3.2 MiB]  17% Done                                 \r",
      "- [17/101 files][681.2 KiB/  3.2 MiB]  20% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00011-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [17/101 files][681.2 KiB/  3.2 MiB]  20% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00012-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [18/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "- [18/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00013-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [19/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "- [19/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "- [20/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00014-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [20/101 files][713.7 KiB/  3.2 MiB]  21% Done                                 \r",
      "- [21/101 files][811.0 KiB/  3.2 MiB]  24% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00015-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [21/101 files][811.0 KiB/  3.2 MiB]  24% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00016-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [22/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "- [22/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "- [23/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00017-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [23/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "- [24/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00018-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [24/101 files][843.4 KiB/  3.2 MiB]  25% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00019-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [25/101 files][875.8 KiB/  3.2 MiB]  26% Done                                 \r",
      "- [25/101 files][875.8 KiB/  3.2 MiB]  26% Done                                 \r",
      "- [26/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00020-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [26/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "- [27/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "- [28/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00021-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00022-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [28/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "- [28/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "- [29/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00023-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [29/101 files][973.2 KiB/  3.2 MiB]  29% Done                                 \r",
      "- [30/101 files][ 1005 KiB/  3.2 MiB]  30% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00024-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [30/101 files][ 1005 KiB/  3.2 MiB]  30% Done                                 \r",
      "\\\r",
      "Copying file://./t2t_data/poetry_line_problem-train-00025-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [31/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "\\ [31/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "\\ [32/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00026-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [32/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "\\ [33/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00027-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [33/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "\\ [34/101 files][  1.1 MiB/  3.2 MiB]  34% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00028-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [34/101 files][  1.1 MiB/  3.2 MiB]  35% Done                                 \r",
      "\\ [35/101 files][  1.2 MiB/  3.2 MiB]  37% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00029-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [35/101 files][  1.2 MiB/  3.2 MiB]  37% Done                                 \r",
      "\\ [36/101 files][  1.2 MiB/  3.2 MiB]  37% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00030-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [36/101 files][  1.2 MiB/  3.2 MiB]  38% Done                                 \r",
      "\\ [37/101 files][  1.2 MiB/  3.2 MiB]  38% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00031-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [37/101 files][  1.2 MiB/  3.2 MiB]  38% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00032-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [38/101 files][  1.3 MiB/  3.2 MiB]  39% Done                                 \r",
      "\\ [38/101 files][  1.3 MiB/  3.2 MiB]  39% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00033-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [39/101 files][  1.3 MiB/  3.2 MiB]  40% Done                                 \r",
      "\\ [39/101 files][  1.3 MiB/  3.2 MiB]  41% Done                                 \r",
      "\\ [40/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00034-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [40/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "\\ [41/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "\\ [42/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00035-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00036-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [42/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "\\ [42/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "\\ [43/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00037-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [43/101 files][  1.4 MiB/  3.2 MiB]  43% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00038-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [44/101 files][  1.4 MiB/  3.2 MiB]  44% Done                                 \r",
      "\\ [44/101 files][  1.5 MiB/  3.2 MiB]  45% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00039-of-00090 [Content-Type=application/octet-stream]...\n",
      "\\ [45/101 files][  1.6 MiB/  3.2 MiB]  48% Done                                 \r",
      "\\ [45/101 files][  1.6 MiB/  3.2 MiB]  48% Done                                 \r",
      "\\ [46/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "|\r",
      "| [47/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [48/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00040-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00041-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00042-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [48/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [48/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [48/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [49/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00043-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00044-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [50/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [50/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "| [50/101 files][  1.6 MiB/  3.2 MiB]  49% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00045-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00046-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [51/101 files][  1.7 MiB/  3.2 MiB]  53% Done                                 \r",
      "| [51/101 files][  1.7 MiB/  3.2 MiB]  53% Done                                 \r",
      "| [52/101 files][  1.7 MiB/  3.2 MiB]  53% Done                                 \r",
      "| [52/101 files][  1.7 MiB/  3.2 MiB]  53% Done                                 \r",
      "| [53/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "| [54/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00047-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00048-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [55/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00049-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [55/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "| [55/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "| [55/101 files][  1.8 MiB/  3.2 MiB]  54% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00050-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [56/101 files][  1.8 MiB/  3.2 MiB]  55% Done                                 \r",
      "| [56/101 files][  1.8 MiB/  3.2 MiB]  55% Done                                 \r",
      "| [57/101 files][  1.9 MiB/  3.2 MiB]  57% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00051-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [57/101 files][  1.9 MiB/  3.2 MiB]  58% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00052-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [58/101 files][  2.0 MiB/  3.2 MiB]  60% Done                                 \r",
      "| [58/101 files][  2.0 MiB/  3.2 MiB]  60% Done                                 \r",
      "| [59/101 files][  2.0 MiB/  3.2 MiB]  60% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00053-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [59/101 files][  2.0 MiB/  3.2 MiB]  60% Done                                 \r",
      "| [60/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00054-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [60/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "| [61/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "| [62/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00055-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00056-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [62/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "| [62/101 files][  2.0 MiB/  3.2 MiB]  61% Done                                 \r",
      "| [63/101 files][  2.1 MiB/  3.2 MiB]  63% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00057-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [63/101 files][  2.1 MiB/  3.2 MiB]  63% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00058-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [64/101 files][  2.2 MiB/  3.2 MiB]  66% Done                                 \r",
      "| [64/101 files][  2.2 MiB/  3.2 MiB]  66% Done                                 \r",
      "| [65/101 files][  2.2 MiB/  3.2 MiB]  66% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00059-of-00090 [Content-Type=application/octet-stream]...\n",
      "| [65/101 files][  2.2 MiB/  3.2 MiB]  66% Done                                 \r",
      "/\r",
      "Copying file://./t2t_data/poetry_line_problem-train-00060-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00062-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00061-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [66/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [67/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [68/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [68/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [68/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [68/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00063-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [69/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [69/101 files][  2.2 MiB/  3.2 MiB]  68% Done                                 \r",
      "/ [70/101 files][  2.3 MiB/  3.2 MiB]  70% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00064-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [70/101 files][  2.3 MiB/  3.2 MiB]  71% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00065-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [71/101 files][  2.4 MiB/  3.2 MiB]  73% Done                                 \r",
      "/ [71/101 files][  2.4 MiB/  3.2 MiB]  73% Done                                 \r",
      "/ [72/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "/ [73/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00066-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [73/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00067-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [73/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "/ [74/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00068-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [74/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "/ [75/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00069-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [75/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "/ [76/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00070-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [76/101 files][  2.4 MiB/  3.2 MiB]  74% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00071-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [77/101 files][  2.6 MiB/  3.2 MiB]  79% Done                                 \r",
      "/ [77/101 files][  2.6 MiB/  3.2 MiB]  79% Done                                 \r",
      "/ [78/101 files][  2.6 MiB/  3.2 MiB]  79% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00072-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [78/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00073-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00074-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00075-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [79/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "/ [80/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "/ [81/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "/ [81/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "/ [81/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "/ [81/101 files][  2.6 MiB/  3.2 MiB]  80% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00076-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [82/101 files][  2.6 MiB/  3.2 MiB]  81% Done                                 \r",
      "/ [82/101 files][  2.6 MiB/  3.2 MiB]  81% Done                                 \r",
      "-\r",
      "Copying file://./t2t_data/poetry_line_problem-train-00077-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [83/101 files][  2.8 MiB/  3.2 MiB]  85% Done                                 \r",
      "- [83/101 files][  2.8 MiB/  3.2 MiB]  85% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00078-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00079-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [84/101 files][  2.8 MiB/  3.2 MiB]  85% Done                                 \r",
      "- [84/101 files][  2.8 MiB/  3.2 MiB]  85% Done                                 \r",
      "- [85/101 files][  2.8 MiB/  3.2 MiB]  85% Done                                 \r",
      "- [85/101 files][  2.8 MiB/  3.2 MiB]  86% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00080-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [86/101 files][  2.8 MiB/  3.2 MiB]  86% Done                                 \r",
      "- [86/101 files][  2.8 MiB/  3.2 MiB]  86% Done                                 \r",
      "- [87/101 files][  2.8 MiB/  3.2 MiB]  86% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00081-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [87/101 files][  2.8 MiB/  3.2 MiB]  86% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00082-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [88/101 files][  2.9 MiB/  3.2 MiB]  90% Done                                 \r",
      "- [88/101 files][  2.9 MiB/  3.2 MiB]  90% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00083-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [89/101 files][  2.9 MiB/  3.2 MiB]  91% Done                                 \r",
      "- [89/101 files][  2.9 MiB/  3.2 MiB]  91% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00084-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [90/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "- [91/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "- [92/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00085-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying file://./t2t_data/poetry_line_problem-train-00086-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [92/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "- [92/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "- [92/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00087-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [93/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "- [93/101 files][  3.0 MiB/  3.2 MiB]  92% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00088-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [94/101 files][  3.1 MiB/  3.2 MiB]  94% Done                                 \r",
      "- [94/101 files][  3.1 MiB/  3.2 MiB]  94% Done                                 \r",
      "Copying file://./t2t_data/poetry_line_problem-train-00089-of-00090 [Content-Type=application/octet-stream]...\n",
      "- [95/101 files][  3.1 MiB/  3.2 MiB]  96% Done                                 \r",
      "- [95/101 files][  3.1 MiB/  3.2 MiB]  96% Done                                 \r",
      "- [96/101 files][  3.1 MiB/  3.2 MiB]  96% Done                                 \r",
      "- [97/101 files][  3.1 MiB/  3.2 MiB]  96% Done                                 \r",
      "Copying file://./t2t_data/vocab.poetry_line_problem.8192.subwords [Content-Type=application/octet-stream]...\n",
      "- [97/101 files][  3.1 MiB/  3.2 MiB]  96% Done                                 \r",
      "- [98/101 files][  3.2 MiB/  3.2 MiB]  97% Done                                 \r",
      "- [99/101 files][  3.2 MiB/  3.2 MiB]  99% Done                                 \r",
      "- [100/101 files][  3.2 MiB/  3.2 MiB]  99% Done                                \r",
      "- [101/101 files][  3.2 MiB/  3.2 MiB] 100% Done                                \r",
      "\\\r\n",
      "Operation completed over 101 objects/3.2 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=./t2t_data\n",
    "gsutil -m rm -r gs://${BUCKET}/poetry/\n",
    "gsutil -m cp ${DATA_DIR}/${PROBLEM}* ${DATA_DIR}/vocab* gs://${BUCKET}/poetry/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorizing the Cloud ML Service account service-977509078434@cloud-ml.google.com.iam.gserviceaccount.com to access files in qwiklabs-gcp-273e0fc7a73ebe0d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   235    0   235    0     0    702      0 --:--:-- --:--:-- --:--:--   703\n",
      "Updated default ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/datalab-backups/us-central1-c/mydatalabvm/content/daily-20190611004026\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/datalab-backups/us-central1-c/mydatalabvm/content/hourly-20190611004026\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00002-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00003-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/datalab-backups/us-central1-c/mydatalabvm/content/weekly-20190611004026\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00000-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00001-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00004-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00006-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00007-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00005-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00008-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00000-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00009-of-00010\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00001-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00002-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00004-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00003-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00006-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00005-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00007-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00008-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00011-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00009-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00010-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00012-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00013-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00015-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00014-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00017-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00016-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00018-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00022-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00020-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00021-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00019-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00023-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00024-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00025-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00027-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00026-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00028-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00031-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00030-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00029-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00032-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00033-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00034-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00035-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00036-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00037-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00038-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00041-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00039-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00040-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00042-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00044-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00043-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00046-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00045-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00047-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00048-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00049-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00050-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00054-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00052-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00053-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00051-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00055-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00056-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00057-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00058-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00060-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00061-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00059-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00062-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00064-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00063-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00066-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00065-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00068-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00067-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00069-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00070-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00071-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00073-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00075-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00074-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00072-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00076-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00077-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00080-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00078-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00079-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00083-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00082-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00081-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00084-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00086-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00085-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00087-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00088-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00089-of-00090\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/vocab.poetry_line_problem.8192.subwords\n",
      "Updated ACL on gs://qwiklabs-gcp-273e0fc7a73ebe0d/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print(response['serviceAccount'])\")\n",
    "\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model locally on subset of data\n",
    "\n",
    "Let's run it locally on a subset of the data to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00080-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 32.4 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00081-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 64.8 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00082-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 97.1 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00083-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/129.5 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00084-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/161.9 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00085-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00086-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00087-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00088-of-00090 [Content-Type=application/octet-stream]...\n",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-train-00089-of-00090 [Content-Type=application/octet-stream]...\n",
      "/ [1/12 files][129.5 KiB/425.2 KiB]  30% Done                                   \r",
      "/ [2/12 files][129.5 KiB/425.2 KiB]  30% Done                                   \r",
      "/ [3/12 files][129.5 KiB/425.2 KiB]  30% Done                                   \r",
      "/ [4/12 files][129.5 KiB/425.2 KiB]  30% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "/ [5/12 files][161.9 KiB/425.2 KiB]  38% Done                                   \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/poetry_line_problem-dev-00000-of-00010 [Content-Type=application/octet-stream]...\n",
      "-\r",
      "- [6/12 files][194.2 KiB/425.2 KiB]  45% Done                                   \r",
      "- [6/12 files][194.2 KiB/425.2 KiB]  45% Done                                   \r",
      "- [7/12 files][226.5 KiB/425.2 KiB]  53% Done                                   \r",
      "Copying gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/data/vocab.poetry_line_problem.8192.subwords [Content-Type=application/octet-stream]...\n",
      "- [7/12 files][226.5 KiB/425.2 KiB]  53% Done                                   \r",
      "- [8/12 files][258.9 KiB/425.2 KiB]  60% Done                                   \r",
      "- [9/12 files][323.8 KiB/425.2 KiB]  76% Done                                   \r",
      "- [10/12 files][323.8 KiB/425.2 KiB]  76% Done                                  \r",
      "- [11/12 files][356.0 KiB/425.2 KiB]  83% Done                                  \r",
      "- [12/12 files][425.2 KiB/425.2 KiB] 100% Done                                  \r\n",
      "Operation completed over 12 objects/425.2 KiB.                                   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BASE=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/subset\n",
    "gsutil -m rm -r $OUTDIR\n",
    "gsutil -m cp \\\n",
    "    ${BASE}/${PROBLEM}-train-0008* \\\n",
    "    ${BASE}/${PROBLEM}-dev-00000*  \\\n",
    "    ${BASE}/vocab* \\\n",
    "    $OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following will work only if you are running Jupyter on a reasonably powerful machine. Don't be alarmed if your process is killed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "I0611 00:49:36.552726 140471131604736 usr_dir.py:43] Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W0611 00:49:36.556653 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "I0611 00:49:36.557090 140471131604736 trainer_lib.py:263] Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "I0611 00:49:36.557243 140471131604736 devices.py:76] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "I0611 00:49:36.557348 140471131604736 devices.py:77] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "I0611 00:49:36.557446 140471131604736 devices.py:78] sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "W0611 00:49:36.557585 140471131604736 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "I0611 00:49:36.558079 140471131604736 devices.py:170] datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "I0611 00:49:36.558198 140471131604736 devices.py:171] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "I0611 00:49:36.558603 140471131604736 devices.py:172] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1cae855d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': './trained_model', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc1cae85610>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "I0611 00:49:37.088165 140471131604736 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1cae855d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': './trained_model', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc1cae85610>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7fc1cae7a758>) includes params argument, but params are not passed to Estimator.\n",
      "W0611 00:49:37.088756 140471131604736 estimator.py:1924] Estimator's model_fn (<function wrapping_model_fn at 0x7fc1cae7a758>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "W0611 00:49:37.089282 140471131604736 trainer_lib.py:721] ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0611 00:49:37.100517 140471131604736 estimator_training.py:185] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0611 00:49:37.101085 140471131604736 training.py:610] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "I0611 00:49:37.101667 140471131604736 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0611 00:49:37.106803 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-train*\n",
      "I0611 00:49:37.119000 140471131604736 problem.py:640] Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "I0611 00:49:37.278844 140471131604736 problem.py:666] partition: 0 num_data_files: 10\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W0611 00:49:37.473247 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:49:37.919667 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:49:38.033620 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0611 00:49:38.109287 140471131604736 estimator.py:1111] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "I0611 00:49:38.125740 140471131604736 t2t_model.py:2089] Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "I0611 00:49:38.503894 140471131604736 optimize.py:358] Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "I0611 00:49:38.598747 140471131604736 t2t_model.py:2089] Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "W0611 00:49:38.777645 140471131604736 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "I0611 00:49:38.786349 140471131604736 t2t_model.py:2089] Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "I0611 00:49:38.801697 140471131604736 t2t_model.py:2089] Building model body\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0611 00:49:38.892103 140471131604736 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8425_128.top\n",
      "I0611 00:49:42.109292 140471131604736 t2t_model.py:2089] Transforming body output with symbol_modality_8425_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "I0611 00:49:42.302911 140471131604736 learning_rate.py:29] Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 2005632\n",
      "I0611 00:49:42.316824 140471131604736 optimize.py:327] Trainable Variables Total size: 2005632\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "I0611 00:49:42.317373 140471131604736 optimize.py:327] Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer adam\n",
      "I0611 00:49:42.317745 140471131604736 optimize.py:182] Using optimizer adam\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0611 00:49:48.182281 140471131604736 estimator.py:1113] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0611 00:49:48.184371 140471131604736 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0611 00:49:51.005960 140471131604736 monitored_session.py:222] Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0611 00:49:52.491180 140471131604736 session_manager.py:491] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0611 00:49:52.683413 140471131604736 session_manager.py:493] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "I0611 00:49:59.740195 140471131604736 basic_session_run_hooks.py:594] Saving checkpoints for 0 into ./trained_model/model.ckpt.\n",
      "2019-06-11 00:50:52.246308: W tensorflow/core/framework/allocator.cc:124] Allocation of 116770500 exceeds 10% of system memory.\n",
      "2019-06-11 00:50:52.646063: W tensorflow/core/framework/allocator.cc:124] Allocation of 116770500 exceeds 10% of system memory.\n",
      "INFO:tensorflow:loss = 8.258053, step = 1\n",
      "I0611 00:50:55.794676 140471131604736 basic_session_run_hooks.py:249] loss = 8.258053, step = 1\n",
      "2019-06-11 00:51:01.933911: W tensorflow/core/framework/allocator.cc:124] Allocation of 113232000 exceeds 10% of system memory.\n",
      "2019-06-11 00:51:02.334364: W tensorflow/core/framework/allocator.cc:124] Allocation of 113232000 exceeds 10% of system memory.\n",
      "2019-06-11 00:51:05.618982: W tensorflow/core/framework/allocator.cc:124] Allocation of 106155000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./trained_model/model.ckpt.\n",
      "I0611 00:51:35.603944 140471131604736 basic_session_run_hooks.py:594] Saving checkpoints for 10 into ./trained_model/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-dev*\n",
      "I0611 00:51:37.144865 140471131604736 problem.py:640] Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "I0611 00:51:37.207570 140471131604736 problem.py:666] partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0611 00:51:37.431642 140471131604736 estimator.py:1111] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "I0611 00:51:37.433335 140471131604736 t2t_model.py:2089] Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "I0611 00:51:37.434174 140471131604736 t2t_model.py:2089] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "I0611 00:51:37.434361 140471131604736 t2t_model.py:2089] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "I0611 00:51:37.434510 140471131604736 t2t_model.py:2089] Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "I0611 00:51:37.434638 140471131604736 t2t_model.py:2089] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "I0611 00:51:37.434751 140471131604736 t2t_model.py:2089] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "I0611 00:51:37.434870 140471131604736 t2t_model.py:2089] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "I0611 00:51:37.992702 140471131604736 optimize.py:358] Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "I0611 00:51:38.083957 140471131604736 t2t_model.py:2089] Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "I0611 00:51:38.290286 140471131604736 t2t_model.py:2089] Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "I0611 00:51:38.304905 140471131604736 t2t_model.py:2089] Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8425_128.top\n",
      "I0611 00:51:41.320019 140471131604736 t2t_model.py:2089] Transforming body output with symbol_modality_8425_128.top\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "W0611 00:51:41.730900 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/rouge.py:235: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0611 00:51:42.265763 140471131604736 estimator.py:1113] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-11T00:51:42Z\n",
      "I0611 00:51:42.292902 140471131604736 evaluation.py:257] Starting evaluation at 2019-06-11T00:51:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0611 00:51:43.398085 140471131604736 monitored_session.py:222] Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0611 00:51:43.399008 140471131604736 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "I0611 00:51:43.400515 140471131604736 saver.py:1270] Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0611 00:51:43.855542 140471131604736 session_manager.py:491] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0611 00:51:43.958467 140471131604736 session_manager.py:493] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-11-00:51:49\n",
      "I0611 00:51:49.847664 140471131604736 evaluation.py:277] Finished evaluation at 2019-06-11-00:51:49\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 9.397356, metrics-poetry_line_problem/targets/accuracy = 0.0013612851, metrics-poetry_line_problem/targets/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/targets/accuracy_top5 = 0.0027225702, metrics-poetry_line_problem/targets/approx_bleu_score = 0.76604635, metrics-poetry_line_problem/targets/neg_log_perplexity = -9.415843, metrics-poetry_line_problem/targets/rouge_2_fscore = 0.8019878, metrics-poetry_line_problem/targets/rouge_L_fscore = 0.82437116\n",
      "I0611 00:51:49.848193 140471131604736 estimator.py:1979] Saving dict for global step 10: global_step = 10, loss = 9.397356, metrics-poetry_line_problem/targets/accuracy = 0.0013612851, metrics-poetry_line_problem/targets/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/targets/accuracy_top5 = 0.0027225702, metrics-poetry_line_problem/targets/approx_bleu_score = 0.76604635, metrics-poetry_line_problem/targets/neg_log_perplexity = -9.415843, metrics-poetry_line_problem/targets/rouge_2_fscore = 0.8019878, metrics-poetry_line_problem/targets/rouge_L_fscore = 0.82437116\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "I0611 00:51:49.849004 140471131604736 estimator.py:2039] Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Loss for final step: 8.247515.\n",
      "I0611 00:51:50.072853 140471131604736 estimator.py:359] Loss for final step: 8.247515.\n",
      "INFO:tensorflow:Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-dev*\n",
      "I0611 00:51:50.085118 140471131604736 problem.py:640] Reading data files from gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/subset/poetry_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 1\n",
      "I0611 00:51:50.145025 140471131604736 problem.py:666] partition: 0 num_data_files: 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0611 00:51:50.413382 140471131604736 estimator.py:1111] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "I0611 00:51:50.415180 140471131604736 t2t_model.py:2089] Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "I0611 00:51:50.415848 140471131604736 t2t_model.py:2089] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "I0611 00:51:50.416007 140471131604736 t2t_model.py:2089] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "I0611 00:51:50.416150 140471131604736 t2t_model.py:2089] Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "I0611 00:51:50.416274 140471131604736 t2t_model.py:2089] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "I0611 00:51:50.416383 140471131604736 t2t_model.py:2089] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "I0611 00:51:50.416516 140471131604736 t2t_model.py:2089] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "I0611 00:51:50.518167 140471131604736 optimize.py:358] Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "I0611 00:51:50.616328 140471131604736 t2t_model.py:2089] Transforming feature 'inputs' with symbol_modality_8425_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "I0611 00:51:50.795710 140471131604736 t2t_model.py:2089] Transforming feature 'targets' with symbol_modality_8425_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "I0611 00:51:50.810331 140471131604736 t2t_model.py:2089] Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8425_128.top\n",
      "I0611 00:51:54.485496 140471131604736 t2t_model.py:2089] Transforming body output with symbol_modality_8425_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0611 00:51:55.410636 140471131604736 estimator.py:1113] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-11T00:51:55Z\n",
      "I0611 00:51:55.434911 140471131604736 evaluation.py:257] Starting evaluation at 2019-06-11T00:51:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0611 00:51:56.075726 140471131604736 monitored_session.py:222] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt-10\n",
      "I0611 00:51:56.077851 140471131604736 saver.py:1270] Restoring parameters from ./trained_model/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0611 00:51:56.610771 140471131604736 session_manager.py:491] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0611 00:51:56.726340 140471131604736 session_manager.py:493] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-11-00:52:02\n",
      "I0611 00:52:02.659940 140471131604736 evaluation.py:277] Finished evaluation at 2019-06-11-00:52:02\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 9.397356, metrics-poetry_line_problem/targets/accuracy = 0.0013612851, metrics-poetry_line_problem/targets/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/targets/accuracy_top5 = 0.0027225702, metrics-poetry_line_problem/targets/approx_bleu_score = 0.76604635, metrics-poetry_line_problem/targets/neg_log_perplexity = -9.415843, metrics-poetry_line_problem/targets/rouge_2_fscore = 0.8019878, metrics-poetry_line_problem/targets/rouge_L_fscore = 0.82437116\n",
      "I0611 00:52:02.660968 140471131604736 estimator.py:1979] Saving dict for global step 10: global_step = 10, loss = 9.397356, metrics-poetry_line_problem/targets/accuracy = 0.0013612851, metrics-poetry_line_problem/targets/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/targets/accuracy_top5 = 0.0027225702, metrics-poetry_line_problem/targets/approx_bleu_score = 0.76604635, metrics-poetry_line_problem/targets/neg_log_perplexity = -9.415843, metrics-poetry_line_problem/targets/rouge_2_fscore = 0.8019878, metrics-poetry_line_problem/targets/rouge_L_fscore = 0.82437116\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n",
      "I0611 00:52:03.550115 140471131604736 estimator.py:2039] Saving 'checkpoint_path' summary for global step 10: ./trained_model/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=gs://${BUCKET}/poetry/subset\n",
    "OUTDIR=./trained_model\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_poetry \\\n",
    "  --output_dir=$OUTDIR --job-dir=$OUTDIR --train_steps=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Train model locally on full dataset (use if running on Notebook Instance with a GPU)\n",
    "\n",
    "You can train on the full dataset if you are on a Google Cloud Notebook Instance with a P100 or better GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "LOCALGPU=\"--train_steps=7500 --worker_gpu=1 --hparams_set=transformer_poetry\"\n",
    "\n",
    "DATA_DIR=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/model\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_poetry \\\n",
    "  --output_dir=$OUTDIR ${LOCALGPU}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Train on Cloud ML Engine\n",
    "\n",
    "tensor2tensor has a convenient --cloud_mlengine option to kick off the training on the managed service.\n",
    "It uses the [Python API](https://cloud.google.com/ml-engine/docs/training-jobs) mentioned in the Cloud ML Engine docs, rather than requiring you to use gcloud to submit the job.\n",
    "<p>\n",
    "Note: your project needs P100 quota in the region.\n",
    "<p>\n",
    "The echo is because t2t-trainer asks you to confirm before submitting the job to the cloud. Ignore any error about \"broken pipe\".\n",
    "If you see a message similar to this:\n",
    "<pre>\n",
    "    [... cloud_mlengine.py:392] Launched transformer_poetry_line_problem_t2t_20190323_000631. See console to track: https://console.cloud.google.com/mlengine/jobs/.\n",
    "</pre>\n",
    "then, this step has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "GPU=\"--train_steps=7500 --cloud_mlengine --worker_gpu=1 --hparams_set=transformer_poetry\"\n",
    "\n",
    "DATADIR=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/model\n",
    "JOBNAME=poetry_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "echo \"'Y'\" | t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  ${GPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "ERROR: (gcloud.ml-engine.jobs.describe) NOT_FOUND: Field: name Error: The specified job was not found.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: The specified job was not found.\n",
      "    field: name\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "## CHANGE the job name (based on output above: You will see a line such as Launched transformer_poetry_line_problem_t2t_20190322_233159)\n",
    "gcloud ml-engine jobs describe transformer_poetry_line_problem_t2t_20190323_003001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job took about <b>25 minutes</b> for me and ended with these evaluation metrics:\n",
    "<pre>\n",
    "Saving dict for global step 8000: global_step = 8000, loss = 6.03338, metrics-poetry_line_problem/accuracy = 0.138544, metrics-poetry_line_problem/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/accuracy_top5 = 0.232037, metrics-poetry_line_problem/approx_bleu_score = 0.00492648, metrics-poetry_line_problem/neg_log_perplexity = -6.68994, metrics-poetry_line_problem/rouge_2_fscore = 0.00256089, metrics-poetry_line_problem/rouge_L_fscore = 0.128194\n",
    "</pre>\n",
    "Notice that accuracy_per_sequence is 0 -- Considering that we are asking the NN to be rather creative, that doesn't surprise me. Why am I looking at accuracy_per_sequence and not the other metrics? This is because it is more appropriate for problem we are solving; metrics like Bleu score are better for translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Train on a directly-connected TPU\n",
    "\n",
    "If you are running on a VM connected directly to a Cloud TPU, you can run t2t-trainer directly. Unfortunately, you won't see any output from Jupyter while the program is running.\n",
    "\n",
    "Compare this command line to the one using GPU in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# use one of these\n",
    "TPU=\"--train_steps=7500 --use_tpu=True --cloud_tpu_name=laktpu --hparams_set=transformer_poetry_tpu\"\n",
    "\n",
    "DATADIR=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/model_tpu\n",
    "JOBNAME=poetry_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "echo \"'Y'\" | t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  ${TPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/poetry/model_tpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job took about <b>10 minutes</b> for me and ended with these evaluation metrics:\n",
    "<pre>\n",
    "Saving dict for global step 8000: global_step = 8000, loss = 6.03338, metrics-poetry_line_problem/accuracy = 0.138544, metrics-poetry_line_problem/accuracy_per_sequence = 0.0, metrics-poetry_line_problem/accuracy_top5 = 0.232037, metrics-poetry_line_problem/approx_bleu_score = 0.00492648, metrics-poetry_line_problem/neg_log_perplexity = -6.68994, metrics-poetry_line_problem/rouge_2_fscore = 0.00256089, metrics-poetry_line_problem/rouge_L_fscore = 0.128194\n",
    "</pre>\n",
    "Notice that accuracy_per_sequence is 0 -- Considering that we are asking the NN to be rather creative, that doesn't surprise me. Why am I looking at accuracy_per_sequence and not the other metrics? This is because it is more appropriate for problem we are solving; metrics like Bleu score are better for translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4: Training longer\n",
    "\n",
    "Let's train on 4 GPUs for 75,000 steps. Note the change in the last line of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "XXX This takes 3 hours on 4 GPUs. Remove this line if you are sure you want to do this.\n",
    "\n",
    "DATADIR=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/model_full2\n",
    "JOBNAME=poetry_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "echo \"'Y'\" | t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_poetry \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --train_steps=75000 --cloud_mlengine --worker_gpu=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This job took <b>12 hours</b> for me and ended with these metrics:\n",
    "<pre>\n",
    "global_step = 76000, loss = 4.99763, metrics-poetry_line_problem/accuracy = 0.219792, metrics-poetry_line_problem/accuracy_per_sequence = 0.0192308, metrics-poetry_line_problem/accuracy_top5 = 0.37618, metrics-poetry_line_problem/approx_bleu_score = 0.017955, metrics-poetry_line_problem/neg_log_perplexity = -5.38725, metrics-poetry_line_problem/rouge_2_fscore = 0.0325563, metrics-poetry_line_problem/rouge_L_fscore = 0.210618\n",
    "</pre>\n",
    "At least the accuracy per sequence is no longer zero. It is now 0.0192308 ... note that we are using a relatively small dataset (12K lines) and this is *tiny* in the world of natural language problems.\n",
    "<p>\n",
    "In order that you have your expectations set correctly: a high-performing translation model needs 400-million lines of input and takes 1 whole day on a TPU pod!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model/t2t_usr_container.tar.gz\n",
      "gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model/tensor2tensor_tmp.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/poetry/model   #_modeltpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-predict\n",
    "\n",
    "How will our poetry model do when faced with Rumi's spiritual couplets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/poetry/rumi.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/poetry/rumi.txt\n",
    "Where did the handsome beloved go?\n",
    "I wonder, where did that tall, shapely cypress tree go?\n",
    "He spread his light among us like a candle.\n",
    "Where did he go? So strange, where did he go without me?\n",
    "All day long my heart trembles like a leaf.\n",
    "All alone at midnight, where did that beloved go?\n",
    "Go to the road, and ask any passing traveler\n",
    "That soul-stirring companion, where did he go?\n",
    "Go to the garden, and ask the gardener\n",
    "That tall, shapely rose stem, where did he go?\n",
    "Go to the rooftop, and ask the watchman\n",
    "That unique sultan, where did he go?\n",
    "Like a madman, I search in the meadows!\n",
    "That deer in the meadows, where did he go?\n",
    "My tearful eyes overflow like a river\n",
    "That pearl in the vast sea, where did he go?\n",
    "All night long, I implore both moon and Venus\n",
    "That lovely face, like a moon, where did he go?\n",
    "If he is mine, why is he with others?\n",
    "Since hes not here, to what there did he go?\n",
    "If his heart and soul are joined with God,\n",
    "And he left this realm of earth and water, where did he go?\n",
    "Tell me clearly, Shams of Tabriz,\n",
    "Of whom it is said, The sun never dieswhere did he go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write out the odd-numbered lines. We'll compare how close our model can get to the beauty of Rumi's second lines given his first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where did the handsome beloved go\n",
      "he spread his light among us like a candle\n",
      "all day long my heart trembles like a leaf\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk 'NR % 2 == 1' data/poetry/rumi.txt | tr '[:upper:]' '[:lower:]' | sed \"s/[^a-z\\'-\\ ]//g\" > data/poetry/rumi_leads.txt\n",
    "head -3 data/poetry/rumi_leads.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "I0611 00:58:22.161451 140485214611200 usr_dir.py:43] Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W0611 00:58:22.609329 140485214611200 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "I0611 00:58:22.609920 140485214611200 trainer_lib.py:263] Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "I0611 00:58:22.610121 140485214611200 devices.py:76] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "I0611 00:58:22.610239 140485214611200 devices.py:77] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "I0611 00:58:22.610337 140485214611200 devices.py:78] sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "W0611 00:58:22.610439 140485214611200 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "I0611 00:58:22.611028 140485214611200 devices.py:170] datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "I0611 00:58:22.611188 140485214611200 devices.py:171] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "I0611 00:58:22.611562 140485214611200 devices.py:172] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc51252ced0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc51252cf10>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "I0611 00:58:22.612337 140485214611200 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc51252ced0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc51252cf10>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7fc51252e758>) includes params argument, but params are not passed to Estimator.\n",
      "W0611 00:58:22.612660 140485214611200 estimator.py:1924] Estimator's model_fn (<function wrapping_model_fn at 0x7fc51252e758>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
      "I0611 00:58:22.613131 140485214611200 decoding.py:401] decode_hp.batch_size not specified; default=32\n",
      "INFO:tensorflow:Performing decoding from file (data/poetry/rumi_leads.txt).\n",
      "I0611 00:58:22.613272 140485214611200 decoding.py:412] Performing decoding from file (data/poetry/rumi_leads.txt).\n",
      "INFO:tensorflow:Getting sorted inputs\n",
      "I0611 00:58:22.613387 140485214611200 decoding.py:855] Getting sorted inputs\n",
      "INFO:tensorflow:Could not find trained model in model_dir: gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model, running initialization to predict.\n",
      "I0611 00:58:22.742278 140485214611200 estimator.py:604] Could not find trained model in model_dir: gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model, running initialization to predict.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0611 00:58:22.756403 140485214611200 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow: batch 1\n",
      "I0611 00:58:22.759033 140485214611200 decoding.py:668]  batch 1\n",
      "INFO:tensorflow:Decoding batch 0\n",
      "I0611 00:58:22.759390 140485214611200 decoding.py:670] Decoding batch 0\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:612: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "W0611 00:58:22.761040 140485214611200 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:612: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:945: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:58:22.764746 140485214611200 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:945: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "W0611 00:58:22.772409 140485214611200 estimator.py:974] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0611 00:58:22.773148 140485214611200 estimator.py:1111] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "I0611 00:58:22.774570 140485214611200 t2t_model.py:2089] Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "I0611 00:58:22.775202 140485214611200 t2t_model.py:2089] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "I0611 00:58:22.775367 140485214611200 t2t_model.py:2089] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "I0611 00:58:22.775515 140485214611200 t2t_model.py:2089] Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "I0611 00:58:22.775643 140485214611200 t2t_model.py:2089] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "I0611 00:58:22.775753 140485214611200 t2t_model.py:2089] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "I0611 00:58:22.775868 140485214611200 t2t_model.py:2089] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n",
      "I0611 00:58:22.872647 140485214611200 t2t_model.py:2089] Beam Decoding with beam size 4\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "W0611 00:58:23.064079 140485214611200 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:853: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:58:23.352294 140485214611200 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:853: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0611 00:58:23.429589 140485214611200 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0611 00:58:26.594039 140485214611200 estimator.py:1113] Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0611 00:58:27.159984 140485214611200 monitored_session.py:222] Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0611 00:58:27.826411 140485214611200 session_manager.py:491] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0611 00:58:27.906668 140485214611200 session_manager.py:493] Done running local_init_op.\n",
      "INFO:tensorflow:Inference results INPUT: he spread his light among us like a candle\n",
      "I0611 00:58:31.721774 140485214611200 decoding.py:150] Inference results INPUT: he spread his light among us like a candle\n",
      "INFO:tensorflow:Inference results OUTPUT: strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "I0611 00:58:31.722690 140485214611200 decoding.py:165] Inference results OUTPUT: strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "INFO:tensorflow:Inference results INPUT: all day long my heart trembles like a leaf\n",
      "I0611 00:58:31.723047 140485214611200 decoding.py:150] Inference results INPUT: all day long my heart trembles like a leaf\n",
      "INFO:tensorflow:Inference results OUTPUT: sitsitsitsitit it it it it it it it it it it un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "I0611 00:58:31.723803 140485214611200 decoding.py:165] Inference results OUTPUT: sitsitsitsitit it it it it it it it it it it un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "INFO:tensorflow:Inference results INPUT: go to the road and ask any passing traveler\n",
      "I0611 00:58:31.724128 140485214611200 decoding.py:150] Inference results INPUT: go to the road and ask any passing traveler\n",
      "INFO:tensorflow:Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "I0611 00:58:31.724884 140485214611200 decoding.py:165] Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "INFO:tensorflow:Inference results INPUT: all night long i implore both moon and venus\n",
      "I0611 00:58:31.725174 140485214611200 decoding.py:150] Inference results INPUT: all night long i implore both moon and venus\n",
      "INFO:tensorflow:Inference results OUTPUT: smosmosmosmosmosmosmosmosmorichly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly\n",
      "I0611 00:58:31.725887 140485214611200 decoding.py:165] Inference results OUTPUT: smosmosmosmosmosmosmosmosmorichly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly\n",
      "INFO:tensorflow:Inference results INPUT: if he is mine why is he with others\n",
      "I0611 00:58:31.726175 140485214611200 decoding.py:150] Inference results INPUT: if he is mine why is he with others\n",
      "INFO:tensorflow:Inference results OUTPUT: strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "I0611 00:58:31.726732 140485214611200 decoding.py:165] Inference results OUTPUT: strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "INFO:tensorflow:Inference results INPUT: if his heart and soul are joined with god\n",
      "I0611 00:58:31.726999 140485214611200 decoding.py:150] Inference results INPUT: if his heart and soul are joined with god\n",
      "INFO:tensorflow:Inference results OUTPUT: sustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale\n",
      "I0611 00:58:31.727663 140485214611200 decoding.py:165] Inference results OUTPUT: sustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale\n",
      "INFO:tensorflow:Inference results INPUT: go to the garden and ask the gardener\n",
      "I0611 00:58:31.727919 140485214611200 decoding.py:150] Inference results INPUT: go to the garden and ask the gardener\n",
      "INFO:tensorflow:Inference results OUTPUT: sustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisun un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "I0611 00:58:31.728615 140485214611200 decoding.py:165] Inference results OUTPUT: sustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisun un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "INFO:tensorflow:Inference results INPUT: go to the rooftop and ask the watchman\n",
      "I0611 00:58:31.728897 140485214611200 decoding.py:150] Inference results INPUT: go to the rooftop and ask the watchman\n",
      "INFO:tensorflow:Inference results OUTPUT: sustsustsustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnois\n",
      "I0611 00:58:31.729517 140485214611200 decoding.py:165] Inference results OUTPUT: sustsustsustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnois\n",
      "INFO:tensorflow:Inference results INPUT: like a madman i search in the meadows\n",
      "I0611 00:58:31.729784 140485214611200 decoding.py:150] Inference results INPUT: like a madman i search in the meadows\n",
      "INFO:tensorflow:Inference results OUTPUT: chryschryschrysstrowstrowstrowstrowstrowstrowstrowstrowstrowstroworcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorckame kame kame kame kame kame kame kame kame kame kame kame\n",
      "I0611 00:58:31.730353 140485214611200 decoding.py:165] Inference results OUTPUT: chryschryschrysstrowstrowstrowstrowstrowstrowstrowstrowstrowstroworcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorckame kame kame kame kame kame kame kame kame kame kame kame\n",
      "INFO:tensorflow:Inference results INPUT: my tearful eyes overflow like a river\n",
      "I0611 00:58:31.730690 140485214611200 decoding.py:150] Inference results INPUT: my tearful eyes overflow like a river\n",
      "INFO:tensorflow:Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "I0611 00:58:31.731422 140485214611200 decoding.py:165] Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "INFO:tensorflow:Inference results INPUT: where did the handsome beloved go\n",
      "I0611 00:58:31.731698 140485214611200 decoding.py:150] Inference results INPUT: where did the handsome beloved go\n",
      "INFO:tensorflow:Inference results OUTPUT: stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare white white white white white sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister\n",
      "I0611 00:58:31.732402 140485214611200 decoding.py:165] Inference results OUTPUT: stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare white white white white white sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister\n",
      "INFO:tensorflow:Inference results INPUT: tell me clearly shams of tabriz\n",
      "I0611 00:58:31.732702 140485214611200 decoding.py:150] Inference results INPUT: tell me clearly shams of tabriz\n",
      "INFO:tensorflow:Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "I0611 00:58:31.733429 140485214611200 decoding.py:165] Inference results OUTPUT: clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "INFO:tensorflow:Elapsed Time: 9.18437\n",
      "I0611 00:58:31.798629 140485214611200 decoding.py:515] Elapsed Time: 9.18437\n",
      "INFO:tensorflow:Averaged Single Token Generation Time: 0.0099861 (time 9.1073041 count 912)\n",
      "I0611 00:58:31.799062 140485214611200 decoding.py:519] Averaged Single Token Generation Time: 0.0099861 (time 9.1073041 count 912)\n",
      "INFO:tensorflow:Inference time 9.1844 seconds (Throughput = 1.3066 sentences/second)\n",
      "I0611 00:58:31.799200 140485214611200 decoding.py:527] Inference time 9.1844 seconds (Throughput = 1.3066 sentences/second)\n",
      "INFO:tensorflow:Writing decodes into data/poetry/rumi_leads.txt.transformer.transformer_poetry.poetry_line_problem.beam4.alpha0.6.decodes\n",
      "I0611 00:58:31.799355 140485214611200 decoding.py:537] Writing decodes into data/poetry/rumi_leads.txt.transformer.transformer_poetry.poetry_line_problem.beam4.alpha0.6.decodes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# same as the above training job ...\n",
    "TOPDIR=gs://${BUCKET}\n",
    "OUTDIR=${TOPDIR}/poetry/model #_tpu  # or ${TOPDIR}/poetry/model_full\n",
    "DATADIR=${TOPDIR}/poetry/data\n",
    "MODEL=transformer\n",
    "HPARAMS=transformer_poetry #_tpu\n",
    "\n",
    "# the file with the input lines\n",
    "DECODE_FILE=data/poetry/rumi_leads.txt\n",
    "\n",
    "BEAM_SIZE=4\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATADIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note </b> if you get an error about \"AttributeError: 'HParams' object has no attribute 'problems'\" please <b>Reset Session</b>, run the cell that defines the PROBLEM and run the above cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare stare white white white white white sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister sister\n",
      "strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "sitsitsitsitit it it it it it it it it it it un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "sustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisun un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un\n",
      "sustsustsustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnois\n",
      "chryschryschrysstrowstrowstrowstrowstrowstrowstrowstrowstrowstroworcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorcorckame kame kame kame kame kame kame kame kame kame kame kame\n",
      "clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n",
      "smosmosmosmosmosmosmosmosmorichly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly richly\n",
      "strowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrowstrow\n",
      "sustsustsustsustsustsustnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisnoisale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale ale\n",
      "clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps clasps\n"
     ]
    }
   ],
   "source": [
    "%%bash  \n",
    "DECODE_FILE=data/poetry/rumi_leads.txt\n",
    "cat ${DECODE_FILE}.*.decodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are still phrases and not complete sentences. This indicates that we might need to train longer or better somehow. We need to diagnose the model ...\n",
    "<p>\n",
    "    \n",
    "### Diagnosing training run\n",
    "\n",
    "<p>\n",
    "Let's diagnose the training run to see what we'd improve the next time around.\n",
    "(Note that this package may not be present on Jupyter -- `pip install pydatalab` if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 30635. Click <a href=\"/_proxy/43567/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30635"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/poetry/model_full2'.format(BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 30635\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"diagrams/poetry_loss.png\"/></td>\n",
    "<td><img src=\"diagrams/poetry_acc.png\"/></td>\n",
    "</table>\n",
    "Looking at the loss curve, it is clear that we are overfitting (note that the orange training curve is well below the blue eval curve). Both loss curves and the accuracy-per-sequence curve, which is our key evaluation measure, plateaus after 40k. (The red curve is a faster way of computing the evaluation metric, and can be ignored). So, how do we improve the model? Well, we need to reduce overfitting and make sure the eval metrics keep going down as long as the loss is also going down.\n",
    "<p>\n",
    "What we really need to do is to get more data, but if that's not an option, we could try to reduce the NN and increase the dropout regularization. We could also do hyperparameter tuning on the dropout and network sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "tensor2tensor also supports hyperparameter tuning on Cloud ML Engine. Note the addition of the autotune flags.\n",
    "<p>\n",
    "The `transformer_poetry_range` was registered in problem.py above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "XXX This takes about 15 hours and consumes about 420 ML units.  Uncomment if you wish to proceed anyway\n",
    "\n",
    "DATADIR=gs://${BUCKET}/poetry/data\n",
    "OUTDIR=gs://${BUCKET}/poetry/model_hparam\n",
    "JOBNAME=poetry_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "echo \"'Y'\" | t2t-trainer \\\n",
    "  --data_dir=gs://${BUCKET}/poetry/subset \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_poetry \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --hparams_range=transformer_poetry_range \\\n",
    "  --autotune_objective='metrics-poetry_line_problem/accuracy_per_sequence' \\\n",
    "  --autotune_maximize \\\n",
    "  --autotune_max_trials=4 \\\n",
    "  --autotune_parallel_trials=4 \\\n",
    "  --train_steps=7500 --cloud_mlengine --worker_gpu=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran the above job, it took about 15 hours and finished with these as the best parameters:\n",
    "<pre>\n",
    "{\n",
    "      \"trialId\": \"37\",\n",
    "      \"hyperparameters\": {\n",
    "        \"hp_num_hidden_layers\": \"4\",\n",
    "        \"hp_learning_rate\": \"0.026711152525921437\",\n",
    "        \"hp_hidden_size\": \"512\",\n",
    "        \"hp_attention_dropout\": \"0.60589466163419292\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"8000\",\n",
    "        \"objectiveValue\": 0.0276162791997\n",
    "      }\n",
    "</pre>\n",
    "In other words, the accuracy per sequence achieved was 0.027 (as compared to 0.019 before hyperparameter tuning, so a <b>40% improvement!</b>) using 4 hidden layers, a learning rate of 0.0267, a hidden size of 512 and droput probability of 0.606. This is inspite of training for only 7500 steps instead of 75,000 steps ... we could train for 75k steps with these parameters, but I'll leave that as an exercise for you.\n",
    "<p>\n",
    "Instead, let's try predicting with this optimized model. Note the addition of the hp* flags in order to override the values hardcoded in the source code. (there is no need to specify learning rate and dropout because they are not used during inference). I am using 37 because I got the best result at trialId=37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "I0611 00:59:01.488729 140105729226496 usr_dir.py:43] Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "INFO:tensorflow:Overriding hparams in transformer_poetry with num_hidden_layers=4,hidden_size=512\n",
      "I0611 00:59:01.490374 140105729226496 hparams_lib.py:55] Overriding hparams in transformer_poetry with num_hidden_layers=4,hidden_size=512\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W0611 00:59:01.837552 140105729226496 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "I0611 00:59:01.838116 140105729226496 trainer_lib.py:263] Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "I0611 00:59:01.838371 140105729226496 devices.py:76] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "I0611 00:59:01.838634 140105729226496 devices.py:77] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "I0611 00:59:01.838782 140105729226496 devices.py:78] sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "W0611 00:59:01.838927 140105729226496 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "I0611 00:59:01.839446 140105729226496 devices.py:170] datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "I0611 00:59:01.839617 140105729226496 devices.py:171] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "I0611 00:59:01.839922 140105729226496 devices.py:172] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6cb739ce50>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_hparam/28', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f6cb739cf10>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "I0611 00:59:01.840703 140105729226496 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6cb739ce50>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_hparam/28', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f6cb739cf10>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7f6cb73a06e0>) includes params argument, but params are not passed to Estimator.\n",
      "W0611 00:59:01.841005 140105729226496 estimator.py:1924] Estimator's model_fn (<function wrapping_model_fn at 0x7f6cb73a06e0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
      "I0611 00:59:01.841514 140105729226496 decoding.py:401] decode_hp.batch_size not specified; default=32\n",
      "INFO:tensorflow:Performing decoding from file (data/poetry/rumi_leads.txt).\n",
      "I0611 00:59:01.841670 140105729226496 decoding.py:412] Performing decoding from file (data/poetry/rumi_leads.txt).\n",
      "INFO:tensorflow:Getting sorted inputs\n",
      "I0611 00:59:01.841774 140105729226496 decoding.py:855] Getting sorted inputs\n",
      "INFO:tensorflow:Could not find trained model in model_dir: gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_hparam/28, running initialization to predict.\n",
      "I0611 00:59:02.010030 140105729226496 estimator.py:604] Could not find trained model in model_dir: gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_hparam/28, running initialization to predict.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0611 00:59:02.023963 140105729226496 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow: batch 1\n",
      "I0611 00:59:02.026626 140105729226496 decoding.py:668]  batch 1\n",
      "INFO:tensorflow:Decoding batch 0\n",
      "I0611 00:59:02.026961 140105729226496 decoding.py:670] Decoding batch 0\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:612: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "W0611 00:59:02.028749 140105729226496 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:612: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:945: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:59:02.032638 140105729226496 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/decoding.py:945: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "W0611 00:59:02.040189 140105729226496 estimator.py:974] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0611 00:59:02.040968 140105729226496 estimator.py:1111] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "I0611 00:59:02.042431 140105729226496 t2t_model.py:2089] Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "I0611 00:59:02.043992 140105729226496 t2t_model.py:2089] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "I0611 00:59:02.044238 140105729226496 t2t_model.py:2089] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "I0611 00:59:02.044382 140105729226496 t2t_model.py:2089] Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "I0611 00:59:02.044522 140105729226496 t2t_model.py:2089] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "I0611 00:59:02.044648 140105729226496 t2t_model.py:2089] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "I0611 00:59:02.044773 140105729226496 t2t_model.py:2089] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n",
      "I0611 00:59:02.143269 140105729226496 t2t_model.py:2089] Beam Decoding with beam size 4\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "W0611 00:59:02.388979 140105729226496 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:853: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0611 00:59:02.657471 140105729226496 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:853: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0611 00:59:02.729980 140105729226496 deprecation.py:506] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/models/transformer.py:93: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0611 00:59:09.019469 140105729226496 estimator.py:1113] Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0611 00:59:09.520014 140105729226496 monitored_session.py:222] Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0611 00:59:10.924916 140105729226496 session_manager.py:491] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0611 00:59:11.065520 140105729226496 session_manager.py:493] Done running local_init_op.\n",
      "INFO:tensorflow:Inference results INPUT: he spread his light among us like a candle\n",
      "I0611 00:59:26.441368 140105729226496 decoding.py:150] Inference results INPUT: he spread his light among us like a candle\n",
      "INFO:tensorflow:Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarsusan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan\n",
      "I0611 00:59:26.442568 140105729226496 decoding.py:165] Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarsusan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan\n",
      "INFO:tensorflow:Inference results INPUT: all day long my heart trembles like a leaf\n",
      "I0611 00:59:26.442907 140105729226496 decoding.py:150] Inference results INPUT: all day long my heart trembles like a leaf\n",
      "INFO:tensorflow:Inference results OUTPUT: cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips\n",
      "I0611 00:59:26.443712 140105729226496 decoding.py:165] Inference results OUTPUT: cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips\n",
      "INFO:tensorflow:Inference results INPUT: go to the road and ask any passing traveler\n",
      "I0611 00:59:26.444011 140105729226496 decoding.py:150] Inference results INPUT: go to the road and ask any passing traveler\n",
      "INFO:tensorflow:Inference results OUTPUT: hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoard\n",
      "I0611 00:59:26.444710 140105729226496 decoding.py:165] Inference results OUTPUT: hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoard\n",
      "INFO:tensorflow:Inference results INPUT: all night long i implore both moon and venus\n",
      "I0611 00:59:26.445013 140105729226496 decoding.py:150] Inference results INPUT: all night long i implore both moon and venus\n",
      "INFO:tensorflow:Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarshine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "I0611 00:59:26.445744 140105729226496 decoding.py:165] Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarshine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "INFO:tensorflow:Inference results INPUT: if he is mine why is he with others\n",
      "I0611 00:59:26.446050 140105729226496 decoding.py:150] Inference results INPUT: if he is mine why is he with others\n",
      "INFO:tensorflow:Inference results OUTPUT: toothtoothtoothtoothtoothtoothtoothtoothtoothtoothtoothdescry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry\n",
      "I0611 00:59:26.446808 140105729226496 decoding.py:165] Inference results OUTPUT: toothtoothtoothtoothtoothtoothtoothtoothtoothtoothtoothdescry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry\n",
      "INFO:tensorflow:Inference results INPUT: if his heart and soul are joined with god\n",
      "I0611 00:59:26.447092 140105729226496 decoding.py:150] Inference results INPUT: if his heart and soul are joined with god\n",
      "INFO:tensorflow:Inference results OUTPUT: rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling dredredredredredredredredredredredredredredredredredredredredredredredredredredre\n",
      "I0611 00:59:26.447808 140105729226496 decoding.py:165] Inference results OUTPUT: rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling dredredredredredredredredredredredredredredredredredredredredredredredredredredre\n",
      "INFO:tensorflow:Inference results INPUT: go to the garden and ask the gardener\n",
      "I0611 00:59:26.448085 140105729226496 decoding.py:150] Inference results INPUT: go to the garden and ask the gardener\n",
      "INFO:tensorflow:Inference results OUTPUT: hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorie\n",
      "I0611 00:59:26.448673 140105729226496 decoding.py:165] Inference results OUTPUT: hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorie\n",
      "INFO:tensorflow:Inference results INPUT: go to the rooftop and ask the watchman\n",
      "I0611 00:59:26.448960 140105729226496 decoding.py:150] Inference results INPUT: go to the rooftop and ask the watchman\n",
      "INFO:tensorflow:Inference results OUTPUT: shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "I0611 00:59:26.450282 140105729226496 decoding.py:165] Inference results OUTPUT: shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "INFO:tensorflow:Inference results INPUT: like a madman i search in the meadows\n",
      "I0611 00:59:26.451699 140105729226496 decoding.py:150] Inference results INPUT: like a madman i search in the meadows\n",
      "INFO:tensorflow:Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstar\n",
      "I0611 00:59:26.452317 140105729226496 decoding.py:165] Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstar\n",
      "INFO:tensorflow:Inference results INPUT: my tearful eyes overflow like a river\n",
      "I0611 00:59:26.452634 140105729226496 decoding.py:150] Inference results INPUT: my tearful eyes overflow like a river\n",
      "INFO:tensorflow:Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthen\n",
      "I0611 00:59:26.453658 140105729226496 decoding.py:165] Inference results OUTPUT: starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthen\n",
      "INFO:tensorflow:Inference results INPUT: where did the handsome beloved go\n",
      "I0611 00:59:26.454298 140105729226496 decoding.py:150] Inference results INPUT: where did the handsome beloved go\n",
      "INFO:tensorflow:Inference results OUTPUT: glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen rounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounroun\n",
      "I0611 00:59:26.455118 140105729226496 decoding.py:165] Inference results OUTPUT: glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen rounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounroun\n",
      "INFO:tensorflow:Inference results INPUT: tell me clearly shams of tabriz\n",
      "I0611 00:59:26.455418 140105729226496 decoding.py:150] Inference results INPUT: tell me clearly shams of tabriz\n",
      "INFO:tensorflow:Inference results OUTPUT: shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "I0611 00:59:26.456208 140105729226496 decoding.py:165] Inference results OUTPUT: shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "INFO:tensorflow:Elapsed Time: 24.72735\n",
      "I0611 00:59:26.570018 140105729226496 decoding.py:515] Elapsed Time: 24.72735\n",
      "INFO:tensorflow:Averaged Single Token Generation Time: 0.0269721 (time 24.5985279 count 912)\n",
      "I0611 00:59:26.570398 140105729226496 decoding.py:519] Averaged Single Token Generation Time: 0.0269721 (time 24.5985279 count 912)\n",
      "INFO:tensorflow:Inference time 24.7273 seconds (Throughput = 0.4853 sentences/second)\n",
      "I0611 00:59:26.570559 140105729226496 decoding.py:527] Inference time 24.7273 seconds (Throughput = 0.4853 sentences/second)\n",
      "INFO:tensorflow:Writing decodes into data/poetry/rumi_leads.txt.transformer.transformer_poetry.poetry_line_problem.beam4.alpha0.6.decodes\n",
      "I0611 00:59:26.570724 140105729226496 decoding.py:537] Writing decodes into data/poetry/rumi_leads.txt.transformer.transformer_poetry.poetry_line_problem.beam4.alpha0.6.decodes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# same as the above training job ...\n",
    "BEST_TRIAL=28  # CHANGE as needed.\n",
    "TOPDIR=gs://${BUCKET}\n",
    "OUTDIR=${TOPDIR}/poetry/model_hparam/$BEST_TRIAL\n",
    "DATADIR=${TOPDIR}/poetry/data\n",
    "MODEL=transformer\n",
    "HPARAMS=transformer_poetry\n",
    "\n",
    "# the file with the input lines\n",
    "DECODE_FILE=data/poetry/rumi_leads.txt\n",
    "\n",
    "BEAM_SIZE=4\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATADIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE \\\n",
    "  --hparams=\"num_hidden_layers=4,hidden_size=512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen glen rounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounrounroun\n",
      "starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarsusan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan susan\n",
      "cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips cowslips\n",
      "hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoard\n",
      "hoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardhoardglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorieglorie\n",
      "shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstar\n",
      "starstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarstarlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthenlengthen\n",
      "starstarstarstarstarstarstarstarstarstarstarstarshine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n",
      "toothtoothtoothtoothtoothtoothtoothtoothtoothtoothtoothdescry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry descry\n",
      "rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling rolling dredredredredredredredredredredredredredredredredredredredredredredredredredredre\n",
      "shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine shine\n"
     ]
    }
   ],
   "source": [
    "%%bash  \n",
    "DECODE_FILE=data/poetry/rumi_leads.txt\n",
    "cat ${DECODE_FILE}.*.decodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the first three line. I'm showing the first line of the couplet provided to the model, how the AI model that we trained complets it and how Rumi completes it:\n",
    "<p>\n",
    "INPUT: where did the handsome beloved go <br/>\n",
    "AI: where art thou worse to me than dead <br/>\n",
    "RUMI: I wonder, where did that tall, shapely cypress tree go?\n",
    "<p>\n",
    "INPUT: he spread his light among us like a candle <br/>\n",
    "AI: like the hurricane eclipse <br/>\n",
    "RUMI: Where did he go? So strange, where did he go without me? <br/>\n",
    "<p>\n",
    "INPUT: all day long my heart trembles like a leaf <br/>\n",
    "AI: and through their hollow aisles it plays <br/>\n",
    "RUMI: All alone at midnight, where did that beloved go? \n",
    "<p>\n",
    "Oh wow. The couplets as completed are quite decent considering that:\n",
    "* We trained the model on American poetry, so feeding it Rumi is a bit out of left field.\n",
    "* Rumi, of course, has a context and thread running through his lines while the AI (since it was fed only that one line) doesn't. \n",
    "\n",
    "<p>\n",
    "\"Spreading light like a hurricane eclipse\" is a metaphor I won't soon forget. And it was created by a machine learning model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving poetry\n",
    "\n",
    "How would you serve these predictions? There are two ways:\n",
    "<ol>\n",
    "<li> Use [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/deploying-models) -- this is serverless and you don't have to manage any infrastructure.\n",
    "<li> Use [Kubeflow](https://github.com/kubeflow/kubeflow/blob/master/user_guide.md) on Google Kubernetes Engine -- this uses clusters but will also work on-prem on your own Kubernetes cluster.\n",
    "</ol>\n",
    "<p>\n",
    "In either case, you need to export the model first and have TensorFlow serving serve the model. The model, however, expects to see *encoded* (i.e. preprocessed) data. So, we'll do that in the Python Flask application (in AppEngine Flex) that serves the user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 00:59:34.680354 140121638766336 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "INFO:tensorflow:Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "I0611 00:59:34.683394 140121638766336 usr_dir.py:43] Importing user module trainer from path /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/09_sequence/poetry\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "W0611 00:59:35.245115 140121638766336 deprecation.py:323] From /usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "I0611 00:59:35.245650 140121638766336 trainer_lib.py:263] Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "I0611 00:59:35.245815 140121638766336 devices.py:76] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "I0611 00:59:35.245927 140121638766336 devices.py:77] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "I0611 00:59:35.246025 140121638766336 devices.py:78] sync=False\n",
      "INFO:tensorflow:datashard_devices: ['']\n",
      "I0611 00:59:35.246126 140121638766336 devices.py:170] datashard_devices: ['']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "I0611 00:59:35.246252 140121638766336 devices.py:171] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "I0611 00:59:35.246726 140121638766336 devices.py:172] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f706b82a290>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_full2', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f706b82a2d0>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "I0611 00:59:35.247606 140121638766336 estimator.py:201] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f706b82a290>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_model_dir': 'gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_full2', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f706b82a2d0>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7f706b8211b8>) includes params argument, but params are not passed to Estimator.\n",
      "W0611 00:59:35.248135 140121638766336 estimator.py:1924] Estimator's model_fn (<function wrapping_model_fn at 0x7f706b8211b8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "I0611 00:59:35.248523 140121638766336 exporter.py:415] Performing the final export in the end of training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/envs/py2env/bin/t2t-exporter\", line 17, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/usr/local/envs/py2env/bin/t2t-exporter\", line 12, in main\n",
      "    export.main(argv)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensor2tensor/serving/export.py\", line 196, in main\n",
      "    is_the_final_export=True)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/exporter.py\", line 419, in export\n",
      "    is_the_final_export)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/exporter.py\", line 126, in export\n",
      "    strip_default_attrs=self._strip_default_attrs)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1645, in export_savedmodel\n",
      "    experimental_mode=model_fn_lib.ModeKeys.PREDICT)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 723, in export_saved_model\n",
      "    checkpoint_path=checkpoint_path)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 801, in experimental_export_all_saved_models\n",
      "    raise ValueError(\"Couldn't find trained model at %s.\" % self._model_dir)\n",
      "ValueError: Couldn't find trained model at gs://qwiklabs-gcp-273e0fc7a73ebe0d/poetry/model_full2.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TOPDIR=gs://${BUCKET}\n",
    "OUTDIR=${TOPDIR}/poetry/model_full2\n",
    "DATADIR=${TOPDIR}/poetry/data\n",
    "MODEL=transformer\n",
    "HPARAMS=transformer_poetry\n",
    "BEAM_SIZE=4\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-exporter \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --t2t_usr_dir=./poetry/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --data_dir=$DATADIR \\\n",
    "  --output_dir=$OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "usage: saved_model_cli show [-h] --dir DIR [--all] [--tag_set TAG_SET]\n",
      "                            [--signature_def SIGNATURE_DEF_KEY]\n",
      "saved_model_cli show: error: argument --dir: expected one argument\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/poetry/model_full2/export | tail -1)\n",
    "echo $MODEL_LOCATION\n",
    "saved_model_cli show --dir $MODEL_LOCATION --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mlengine.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile mlengine.json\n",
    "description: Poetry service on ML Engine\n",
    "autoScaling:\n",
    "    minNodes: 1  # We don't want this model to autoscale down to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying poetry v1 from  ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n",
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "This will delete version [v1]...\n",
      "\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  Please enter 'y' or 'n':  Please enter 'y' or 'n':  Please enter 'y' or 'n':  \n",
      "ERROR: (gcloud.ml-engine.versions.delete) NOT_FOUND: Field: name Error: The model resource: \"poetry\" was not found. Please create the Cloud ML model resource first by using 'gcloud ml-engine models create poetry'.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: \"The model resource: \\\"poetry\\\" was not found. Please create the\\\n",
      "      \\ Cloud ML model resource first by using 'gcloud ml-engine models create poetry'.\"\n",
      "    field: name\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"poetry\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/poetry/model_full2/export | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} \\\n",
    "       --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=1.13 --config=mlengine.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kubeflow\n",
    "\n",
    "Follow these instructions:\n",
    "* On the GCP console, launch a Google Kubernetes Engine (GKE) cluster named 'poetry' with 2 nodes, each of which is a n1-standard-2 (2 vCPUs, 7.5 GB memory) VM\n",
    "* On the GCP console, click on the Connect button for your cluster, and choose the CloudShell option\n",
    "* In CloudShell, run: \n",
    "    ```\n",
    "    git clone https://github.com/GoogleCloudPlatform/training-data-analyst`\n",
    "    cd training-data-analyst/courses/machine_learning/deepdive/09_sequence\n",
    "    ```\n",
    "* Look at [`./setup_kubeflow.sh`](setup_kubeflow.sh) and modify as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AppEngine\n",
    "\n",
    "What's deployed in Cloud ML Engine or Kubeflow is only the TensorFlow model. We still need a preprocessing service. That is done using AppEngine.  Edit application/app.yaml appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: python\r\n",
      "env: flex\r\n",
      "entrypoint: gunicorn -b :$PORT main:app\r\n",
      "service: mlpoetry\r\n",
      "\r\n",
      "handlers:\r\n",
      "- url: /\r\n",
      "  script: main.app\r\n",
      "- url: /.*\r\n",
      "  script: main.app\r\n",
      "\r\n",
      "env_variables:\r\n",
      "  MODEL_NAME: poetry\r\n",
      "  PROJECT_ID: cloud-training-demos\r\n",
      "  VERSION_NAME: v1\r\n",
      "  PROBLEM_NAME: poetry_line_problem\r\n",
      "  T2T_USR_DIR: instance/poetry/trainer\r\n",
      "  HPARAMS: transformer_poetry\r\n",
      "  DATADIR: gs://cloud-training-demos-ml/poetry/data\r\n"
     ]
    }
   ],
   "source": [
    "!cat application/app.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd application\n",
    "#gcloud app create  # if this is your first app\n",
    "#gcloud app deploy --quiet --stop-previous-version app.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visit https://mlpoetry-dot-cloud-training-demos.appspot.com and try out the prediction app!\n",
    "\n",
    "<img src=\"diagrams/poetry_app.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
